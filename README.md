# Оптимизация и lightweight-версия трансформерной модели для классификации текстов на русском языке

**Описание работы**: Оптимизация модели по определению тональности текста и ускорение её работы, а также анализ методов оптимизации.

## Навигация по документации:
- [Введение](#введение)
- [Проведенные работы](#проведенные-работы)
- [Сравнительный анализ выбранных комбинаций для исследования](#сравнительный-анализ-выбранных-комбинаций-для-исследования)
- [Характеристики устройства, на котором проводились исследования](#характеристики-устройства-на-котором-проводились-исследования)
- [Сравнение 4 полученных моделей](#сравнение-4-полученных-моделей)
- [Вывод](#вывод)
---

## Введение
  Одним из перспективных направлений прикладных ML/AI продолжает оставаться классификация текстов на русском языке. Каждый день различные онлайн-сервисы обрабатывают текст, отправленный пользователем, будь это сообщение в чате или отзыв на маркетплейсе. Определение тональности текста является важной задачей для таких сервисов, как «Яндекс.Маркет», «Яндекс.Дзен», «Алиса» и т.д. в части более точного определения рекомендаций и улучшения взаимодействия с пользователем.
Хоть и задача по определению тональности текста и речи в настоящее время имеет множество решений, в рамках данной работы сделан акцент на оптимизацию и ускорение работы модели для классификации текста на русском языке. Современные модели BERT (RuBERT) могут показывать отличные результаты по определению тональности текста. Однако данные модели имеют большой размер и высокие требования к вычислительным ресурсам, что является препятствием для использования этих моделей в мобильных устройствах и голосовых помощниках, таких как, «Алиса».
Целью работы является оптимизация модели по определению тональности текста и ускорение её работы, а также анализ методов оптимизации.
Решение данной проблемы является корнем для обсуждения следующих работ, которые могут получить дополнительную прибыль и/или оптимизировать рынок труда:
- предсказание цен на акции, учитывая новостной фон;
- внутренняя оценка товаров по анализу отзывов на маркетплейсах;
-  модель выбора стратегии общения оператора в колл-центре по эмоциональному настроению клиента;
- и т.д.

## Проведенные работы
- проанализированы методы оптимизации моделей, архитектуры трансформеров и их русскоязычные версии;
- проведен анализ датасетов (использованные датасеты: https://github.com/strawberrypie/rusentiment) и их предобработка;
- проанализировано распределение 5 классов тональности (negative, neutral, positive, skip, speech);
- проведено дообучение модели rubert-tiny2;
- разработана архитектура students с уменьшенными параметрами (описание конфигураций далее);
- проведена квантизация и дистиляция моделей;
- проведено сравнение 4 конфигураций: Teacher, Teacher+PTQ, Student, Student+PTQ;
- выведены графики для конфигураций. 

## Сравнительный анализ выбранных комбинаций для исследования
*Комбинация - Teacher*.
Описание - исходная модель rubert-tiny2, архитектура не изменяется, квантизация отсутсвует(float32).
Причина выбора - исходная модель, для фиксации и сравнения с последующими оптимизационными моделями.

*Комбинация - Teacher + PTQ*.
Описание - то же, с добавлением посттрекинговой квантизацией int8.
Причина выбора - для определения эффекта от посттрекинговой квантизации int8 с изначальной архитектурой.

*Комбинация - Student*.
Описание - сокращенная архитектура, обученная методом дисциляции, 5 классов тональности, float32.
Причина выбора - для оценки эффективности модели только от сжатия архитектуры учителя.

*Комбинация - Student + PTQ*.
Описание - то же, с добавлением посттрекинговой квантизацией int8.
Причина выбора - для оценки эффективности от комбинированного метода.
  
## Характеристики устройства, на котором проводились исследования
- Процессор - 13th Gen Intel(R) Core(TM) i7-1360P 2.20 GHz
- Оперативная память, Гб - 16,0
- Видеокарта - Intel(R) Iris(R) Xe Graphics
- Операционная система - Windows 11
- Версия Python - Python 3.12.3

## Сравнение 4 полученных моделей
|Модель|Размер|Скорость|Accuracy|Параметров|Сжатие|Ускорение|
|---|---|---|---|---|---|---|
|teacher|111.4|356.0|53.45|29195333|1.000000|1.000000|
|teacher + PTQ|104.6|866.0|53.45|26798304|1.065010|0.411085|
|student|90.2|283.7|51.0|23631877|1.235033|1.254847|
|student + PTQ|85.5|535.4|51.25|21987328|1.302924|0.664923|

## Вывод
Представленные метрики показывают, что оптимизация дистиляцией и квантизацией позволила значительно уменьшить размер модели и скорость обучения при незначительных потерях точности (потеря составила 2 процента).
P.S. предыдущие прогоны показывали результаты лучше:
|Модель|Размер|Скорость|Accuracy|Параметров|Сжатие|Ускорение|
|---|---|---|---|---|---|---|
|teacher|111.4|421.9|51.25|29195333|1.000000|1.000000|
|teacher + PTQ|104.6|856.5|50.96|26798304|1.065010|0.492586|
|student|90.2|437.9|51.63|23631877|1.235033|0.963462|
|student + PTQ|85.5|596.9|51.82|21987328|1.302924|0.706819|
